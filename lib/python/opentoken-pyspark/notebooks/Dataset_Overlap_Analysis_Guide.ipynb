{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overlap Analysis Guide\n",
    "\n",
    "This notebook demonstrates how to use the `OpenTokenOverlapAnalyzer` class to identify matching records between two tokenized datasets.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The OpenTokenOverlapAnalyzer helps you:\n",
    "- Find matching records across two datasets based on encrypted tokens\n",
    "- Define flexible matching rules (which token types must match)\n",
    "- Compare overlap rates using different matching criteria\n",
    "- Get detailed statistics and matched record pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from opentoken_pyspark import OpenTokenProcessor, OpenTokenOverlapAnalyzer\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"OverlapAnalysisExample\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set secrets (use the same secrets for both datasets!)\n",
    "HASHING_SECRET = \"my-hashing-secret-key\"\n",
    "ENCRYPTION_KEY = \"my-encryption-key-32-characters!\"  # Must be 32 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Datasets\n",
    "\n",
    "Let's create two datasets representing patient records from different hospitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital A data\n",
    "hospital_a_data = [\n",
    "    (\"A001\", \"John\", \"Doe\", \"1990-01-15\", \"Male\", \"98101\", \"123-45-6789\"),\n",
    "    (\"A002\", \"Jane\", \"Smith\", \"1985-06-20\", \"Female\", \"94105\", \"987-65-4321\"),\n",
    "    (\"A003\", \"Bob\", \"Johnson\", \"1978-03-10\", \"Male\", \"02134\", \"456-78-9123\"),\n",
    "    (\"A004\", \"Alice\", \"Williams\", \"1992-11-05\", \"Female\", \"10001\", \"321-54-9876\"),\n",
    "    (\"A005\", \"Charlie\", \"Brown\", \"1988-08-22\", \"Male\", \"60614\", \"789-12-3456\"),\n",
    "]\n",
    "\n",
    "hospital_a_df = spark.createDataFrame(\n",
    "    hospital_a_data,\n",
    "    [\"RecordId\", \"FirstName\", \"LastName\", \"BirthDate\", \"Sex\", \"PostalCode\", \"SocialSecurityNumber\"]\n",
    ")\n",
    "\n",
    "print(\"Hospital A Records:\")\n",
    "hospital_a_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital B data (has some overlapping patients)\n",
    "hospital_b_data = [\n",
    "    (\"B101\", \"John\", \"Doe\", \"1990-01-15\", \"Male\", \"98101\", \"123-45-6789\"),     # Same as A001\n",
    "    (\"B102\", \"Jane\", \"Smith\", \"1985-06-20\", \"Female\", \"94105\", \"987-65-4321\"),  # Same as A002\n",
    "    (\"B103\", \"David\", \"Lee\", \"1995-04-18\", \"Male\", \"30303\", \"654-32-1098\"),     # Unique to B\n",
    "    (\"B104\", \"Emma\", \"Davis\", \"1982-12-30\", \"Female\", \"90210\", \"234-56-7890\"),  # Unique to B\n",
    "]\n",
    "\n",
    "hospital_b_df = spark.createDataFrame(\n",
    "    hospital_b_data,\n",
    "    [\"RecordId\", \"FirstName\", \"LastName\", \"BirthDate\", \"Sex\", \"PostalCode\", \"SocialSecurityNumber\"]\n",
    ")\n",
    "\n",
    "print(\"Hospital B Records:\")\n",
    "hospital_b_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tokens for Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize token processor\n",
    "processor = OpenTokenProcessor(HASHING_SECRET, ENCRYPTION_KEY)\n",
    "\n",
    "# Generate tokens for Hospital A\n",
    "hospital_a_tokens = processor.process_dataframe(hospital_a_df)\n",
    "print(\"Hospital A Tokens:\")\n",
    "hospital_a_tokens.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tokens for Hospital B\n",
    "hospital_b_tokens = processor.process_dataframe(hospital_b_df)\n",
    "print(\"Hospital B Tokens:\")\n",
    "hospital_b_tokens.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Dataset Overlap\n",
    "\n",
    "### Method 1: Single Rule Set\n",
    "\n",
    "Let's find matches requiring T1 and T2 tokens to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize overlap analyzer with the same encryption key\n",
    "analyzer = OpenTokenOverlapAnalyzer(ENCRYPTION_KEY)\n",
    "\n",
    "# Analyze overlap with T1 and T2 matching rules\n",
    "results = analyzer.analyze_overlap(\n",
    "    hospital_a_tokens,\n",
    "    hospital_b_tokens,\n",
    "    matching_rules=[\"T1\", \"T2\"],\n",
    "    dataset1_name=\"Hospital_A\",\n",
    "    dataset2_name=\"Hospital_B\"\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "analyzer.print_summary(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Matched Record Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show matched record pairs\n",
    "print(\"Matched Record Pairs:\")\n",
    "results['matches'].show()\n",
    "\n",
    "# Expected: Should show A001<->B101 and A002<->B102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check if decryption is working in the analyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Test the decrypt method manually\n",
    "analyzer = OpenTokenOverlapAnalyzer(ENCRYPTION_KEY)\n",
    "test_token = hospital_a_tokens.select(\"Token\").filter(\"RuleId == 'T1'\").first()[\"Token\"]\n",
    "print(f\"Sample Token: {test_token}\")\n",
    "print(f\"Decrypted: {analyzer._decrypt_token(test_token)}\")\n",
    "\n",
    "# Check if UDF is working\n",
    "decrypt_udf = udf(analyzer._decrypt_token, StringType())\n",
    "hospital_a_tokens.withColumn(\"Decrypted\", decrypt_udf(\"Token\")).select(\"RuleId\", \"Token\", \"Decrypted\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Compare Multiple Rule Sets\n",
    "\n",
    "Let's see how overlap changes with different matching criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different rule sets to compare\n",
    "rule_sets = [\n",
    "    [\"T1\"],              # Least strict: only T1 must match\n",
    "    [\"T1\", \"T2\"],        # Medium: T1 AND T2 must match\n",
    "    [\"T1\", \"T2\", \"T3\"],  # Strict: T1 AND T2 AND T3 must match\n",
    "    [\"T1\", \"T2\", \"T3\", \"T4\"],  # Very strict: all 4 tokens must match\n",
    "]\n",
    "\n",
    "# Run comparison\n",
    "multi_results = analyzer.compare_with_multiple_rules(\n",
    "    hospital_a_tokens,\n",
    "    hospital_b_tokens,\n",
    "    rule_sets,\n",
    "    dataset1_name=\"Hospital_A\",\n",
    "    dataset2_name=\"Hospital_B\"\n",
    ")\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\nOverlap Comparison Across Different Matching Rules:\")\n",
    "print(\"=\" * 70)\n",
    "for result in multi_results:\n",
    "    rules_str = \", \".join(result['matching_rules'])\n",
    "    print(f\"Rules: {rules_str:20} | \"\n",
    "          f\"Matches: {result['matching_records_dataset1']:2} | \"\n",
    "          f\"Overlap: {result['overlap_percentage']:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Detailed Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access detailed statistics from any result\n",
    "result = multi_results[1]  # T1 + T2 result\n",
    "\n",
    "print(f\"Dataset: {result['dataset1_name']}\")\n",
    "print(f\"  Total records: {result['total_records_dataset1']}\")\n",
    "print(f\"  Matching records: {result['matching_records_dataset1']}\")\n",
    "print(f\"  Unique records: {result['unique_to_dataset1']}\")\n",
    "print()\n",
    "print(f\"Dataset: {result['dataset2_name']}\")\n",
    "print(f\"  Total records: {result['total_records_dataset2']}\")\n",
    "print(f\"  Matching records: {result['matching_records_dataset2']}\")\n",
    "print(f\"  Unique records: {result['unique_to_dataset2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Analyzing Data Sharing Potential\n",
    "\n",
    "Let's say you want to assess whether two institutions should establish a data sharing agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze with strict matching criteria\n",
    "strict_results = analyzer.analyze_overlap(\n",
    "    hospital_a_tokens,\n",
    "    hospital_b_tokens,\n",
    "    matching_rules=[\"T1\", \"T2\", \"T3\"],  # Require 3 token types to match\n",
    "    dataset1_name=\"Hospital_A\",\n",
    "    dataset2_name=\"Hospital_B\"\n",
    ")\n",
    "\n",
    "# Decision logic\n",
    "overlap_pct = strict_results['overlap_percentage']\n",
    "unique_a = strict_results['unique_to_dataset1']\n",
    "unique_b = strict_results['unique_to_dataset2']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA SHARING ASSESSMENT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Overlap: {overlap_pct:.1f}%\")\n",
    "print(f\"Unique records in Hospital A: {unique_a}\")\n",
    "print(f\"Unique records in Hospital B: {unique_b}\")\n",
    "print()\n",
    "\n",
    "if overlap_pct < 10:\n",
    "    print(\"✓ RECOMMENDATION: High potential for data sharing\")\n",
    "    print(\"  Minimal overlap suggests complementary patient populations.\")\n",
    "elif overlap_pct < 30:\n",
    "    print(\"✓ RECOMMENDATION: Moderate potential for data sharing\")\n",
    "    print(\"  Some overlap exists but substantial unique populations in each dataset.\")\n",
    "else:\n",
    "    print(\"⚠ RECOMMENDATION: Review data sharing need carefully\")\n",
    "    print(\"  Significant overlap may reduce value of data sharing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Encryption Key**: Must be the same key used to generate tokens\n",
    "2. **Matching Rules**: Define which token types must match (ALL must match, not just one)\n",
    "3. **Multiple Criteria**: Use `compare_with_multiple_rules()` to see how overlap changes with stricter matching\n",
    "4. **Privacy**: Analysis uses encrypted tokens - no PHI is exposed\n",
    "5. **Results**: Get both statistics and detailed matched record pairs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try with your own datasets\n",
    "- Experiment with different token rule combinations\n",
    "- Use custom token definitions (see Custom_Token_Definition_Guide.ipynb)\n",
    "- Scale to larger datasets using your Spark cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
