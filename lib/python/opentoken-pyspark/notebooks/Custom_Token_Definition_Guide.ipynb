{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Token Definition Guide\n",
    "\n",
    "This notebook demonstrates how to create custom token definitions with minimal code using the OpenToken notebook helpers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentoken.notebook_helpers import (\n",
    "    TokenBuilder,\n",
    "    CustomTokenDefinition,\n",
    "    create_token_generator,\n",
    "    quick_token,\n",
    "    list_attributes,\n",
    "    expression_help\n",
    ")\n",
    "from opentoken.attributes.general.record_id_attribute import RecordIdAttribute\n",
    "from opentoken.attributes.person.first_name_attribute import FirstNameAttribute\n",
    "from opentoken.attributes.person.last_name_attribute import LastNameAttribute\n",
    "from opentoken.attributes.person.birth_date_attribute import BirthDateAttribute\n",
    "from opentoken.attributes.person.sex_attribute import SexAttribute\n",
    "from opentoken.attributes.person.postal_code_attribute import PostalCodeAttribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Available Attributes\n",
    "\n",
    "Check what attributes are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = list_attributes()\n",
    "print(\"Available attributes:\")\n",
    "for name in attrs.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Syntax Help\n",
    "\n",
    "Get help on expression syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expression_help())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Quick Token (Simplest)\n",
    "\n",
    "Create a custom T6 token in one line with the rule:\n",
    "`U(last-name)|U(first-name)|birth-date|postal-code-3|U(sex)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create T6 token generator in one call\n",
    "generator = quick_token(\n",
    "    \"T6\",\n",
    "    [\n",
    "        (\"last_name\", \"T|U\"),\n",
    "        (\"first_name\", \"T|U\"),\n",
    "        (\"birth_date\", \"T|D\"),\n",
    "        (\"postal_code\", \"T|S(0,3)\"),\n",
    "        (\"sex\", \"T|U\")\n",
    "    ],\n",
    "    \"my-hashing-secret\",\n",
    "    \"my-32-character-encryption-key!\"\n",
    ")\n",
    "\n",
    "# Test it with sample data\n",
    "person_attrs = {\n",
    "    RecordIdAttribute: \"1\",\n",
    "    FirstNameAttribute: \"John\",\n",
    "    LastNameAttribute: \"Doe\",\n",
    "    BirthDateAttribute: \"1990-01-15\",\n",
    "    SexAttribute: \"Male\",\n",
    "    PostalCodeAttribute: \"98101\"\n",
    "}\n",
    "\n",
    "result = generator.get_all_tokens(person_attrs)\n",
    "print(f\"T6 Token: {result.tokens.get('T6')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Token Builder (More Flexible)\n",
    "\n",
    "Use the fluent TokenBuilder API for more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom T6 token\n",
    "t6_token = TokenBuilder(\"T6\") \\\n",
    "    .add(\"last_name\", \"T|U\") \\\n",
    "    .add(\"first_name\", \"T|U\") \\\n",
    "    .add(\"birth_date\", \"T|D\") \\\n",
    "    .add(\"postal_code\", \"T|S(0,3)\") \\\n",
    "    .add(\"sex\", \"T|U\") \\\n",
    "    .build()\n",
    "\n",
    "# Create a custom token definition\n",
    "custom_definition = CustomTokenDefinition().add_token(t6_token)\n",
    "\n",
    "# Create token generator\n",
    "generator = create_token_generator(\n",
    "    \"my-hashing-secret\",\n",
    "    \"my-32-character-encryption-key!\",\n",
    "    custom_definition\n",
    ")\n",
    "\n",
    "# Generate tokens\n",
    "result = generator.get_all_tokens(person_attrs)\n",
    "print(f\"T6 Token: {result.tokens.get('T6')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Multiple Custom Tokens\n",
    "\n",
    "Define multiple tokens in one definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create T6 token: U(last-name)|U(first-name)|birth-date|postal-code-3|U(sex)\n",
    "t6_token = TokenBuilder(\"T6\") \\\n",
    "    .add(\"last_name\", \"T|U\") \\\n",
    "    .add(\"first_name\", \"T|U\") \\\n",
    "    .add(\"birth_date\", \"T|D\") \\\n",
    "    .add(\"postal_code\", \"T|S(0,3)\") \\\n",
    "    .add(\"sex\", \"T|U\") \\\n",
    "    .build()\n",
    "\n",
    "# Create T7 token: U(last-name-3)|U(first-name-3)|birth-date\n",
    "t7_token = TokenBuilder(\"T7\") \\\n",
    "    .add(\"last_name\", \"T|S(0,3)|U\") \\\n",
    "    .add(\"first_name\", \"T|S(0,3)|U\") \\\n",
    "    .add(\"birth_date\", \"T|D\") \\\n",
    "    .build()\n",
    "\n",
    "# Add both tokens to definition\n",
    "custom_definition = CustomTokenDefinition() \\\n",
    "    .add_token(t6_token) \\\n",
    "    .add_token(t7_token)\n",
    "\n",
    "# Create generator\n",
    "generator = create_token_generator(\n",
    "    \"my-hashing-secret\",\n",
    "    \"my-32-character-encryption-key!\",\n",
    "    custom_definition\n",
    ")\n",
    "\n",
    "# Generate both tokens\n",
    "result = generator.get_all_tokens(person_attrs)\n",
    "print(f\"T6 Token: {result.tokens.get('T6')}\")\n",
    "print(f\"T7 Token: {result.tokens.get('T7')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with PySpark DataFrames\n",
    "\n",
    "Integrate custom tokens with the PySpark processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from opentoken_pyspark import OpenTokenProcessor\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"CustomTokens\").getOrCreate()\n",
    "\n",
    "# Create sample DataFrame\n",
    "data = [\n",
    "    (\"1\", \"John\", \"Doe\", \"1990-01-15\", \"Male\", \"98101\"),\n",
    "    (\"2\", \"Jane\", \"Smith\", \"1985-06-20\", \"Female\", \"94105\")\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"RecordId\", \"FirstName\", \"LastName\", \"BirthDate\", \"Sex\", \"PostalCode\"])\n",
    "\n",
    "# Note: Currently OpenTokenProcessor uses the default token definition\n",
    "# For custom tokens, you would process rows individually as shown above\n",
    "# Future enhancement: Allow passing custom token definition to OpenTokenProcessor\n",
    "\n",
    "print(\"Sample data:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Different Rules\n",
    "\n",
    "Try different combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal token: just last name and first initial\n",
    "minimal_token = TokenBuilder(\"MINIMAL\") \\\n",
    "    .add(\"last_name\", \"T|U\") \\\n",
    "    .add(\"first_name\", \"T|S(0,1)|U\") \\\n",
    "    .build()\n",
    "\n",
    "# Full token: everything\n",
    "full_token = TokenBuilder(\"FULL\") \\\n",
    "    .add(\"last_name\", \"T|U\") \\\n",
    "    .add(\"first_name\", \"T|U\") \\\n",
    "    .add(\"birth_date\", \"T|D\") \\\n",
    "    .add(\"sex\", \"T|U\") \\\n",
    "    .add(\"postal_code\", \"T|S(0,5)\") \\\n",
    "    .add(\"ssn\", \"T\") \\\n",
    "    .build()\n",
    "\n",
    "# Create definition with both\n",
    "definition = CustomTokenDefinition() \\\n",
    "    .add_token(minimal_token) \\\n",
    "    .add_token(full_token)\n",
    "\n",
    "generator = create_token_generator(\n",
    "    \"my-hashing-secret\",\n",
    "    \"my-32-character-encryption-key!\",\n",
    "    definition\n",
    ")\n",
    "\n",
    "result = generator.get_all_tokens(person_attrs)\n",
    "print(f\"Minimal Token: {result.tokens.get('MINIMAL')}\")\n",
    "print(f\"Full Token: {result.tokens.get('FULL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Three ways to create custom tokens:\n",
    "\n",
    "1. **`quick_token()`** - Fastest, one-liner approach for simple cases\n",
    "2. **`TokenBuilder`** - Fluent API for readable, flexible definitions\n",
    "3. **Manual classes** - Full control (as shown in previous examples)\n",
    "\n",
    "Choose the method that best fits your workflow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OpenToken)",
   "language": "python",
   "name": "opentoken"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
